
1、实时数仓的意义
目前广泛使用离线数仓的数据反映的是一段相当长的时间内历史数据的内容，是不同时点的数据库快照的集合，反应历史变化。

同时，离线数仓主要基于大数据的体系的分布式文件处理实现，主要是批处理，对处理的性能以及数据的实时准确性不存在过高要求；



对于实时性要求比较高的场景，如实时的交易分析、实时数据看板（比如双十一的成交额看板）、实时业务监控、实时数据接口服务等，传统T+1离线数仓，很难满足对数据的需求，这个时候实时数仓就应运而生了。

举个简单的例子：

在滴滴的打车业务中采用实时数仓，可以知道某个时间点某个区域的乘客发单情况、司机应答情况，从而采取对应的优惠券触发或加派司机进行调度支持等策略，系统通过实时数仓发现该时间点乘客较少、司机比较空闲，于是通过比较优惠价格，提高乘客打车欲望、增加司机收入。

2、数仓系统整体架构设计




3、技术选型
3.1  数仓载体-分析型数据库AnalyticDB for MySQL 2.0
云原生数据仓库AnalyticDB MySQL版是融合数据库、大数据技术于一体的云原生企业级数据仓库服务。

AnalyticDB MySQL版支持高吞吐的数据实时增删改、低延时的实时分析和复杂ETL，兼容上下游生态工具，可用于构建企业级报表系统、数据仓库和数据服务引擎。

AnalyticDB MySQL版运用新一代超大规模的MPP+DAG融合引擎，采用行列混存技术、自动索引、智能优化器，支持毫秒/秒级对海量数据进行查询和计算，复杂SQL查询速度相比传统的关系型数据库快10倍。

AnalyticDB MySQL版采用RAFT协议，支持超大规模数据写入实时、强一致，数据实时写入实时可见；对于高并发或大吞吐场景，可按需独立弹性扩展，存储可以从GB级扩展到百PB级，TPS可横向扩展至千万级。

官方介绍：https://help.aliyun.com/document_detail/93776.html?spm=a2c4g.11186623.6.547.5cd02eb47sXe9p

3.2  数仓元数据存储-mysql
MySQL是一种关系型数据库管理系统，具有数据库体积小、速度快、总体拥有成本低的优点。

数仓元数据作为一种轻量级的数据，以mysql作为元数据载体能够发挥出较好的性能。

3.3  调度器-Schedulerx
分布式任务调度 SchedulerX 2.0 是阿里巴巴基于 Akka 架构自研的新一代分布式任务调度平台。 

SchedulerX主要提供调度、执行和运维三方面的功能，可以在控制台配置、管理的定时调度任务、查询任务执行记录和运行日志，还可以通过工作流进行任务编排和数据传递。

SchedulerX提供了简单、易用的分布式编程模型，通过简单几行代码就可以将海量数据分发到多台机器上执行。

官方介绍：https://help.aliyun.com/document_detail/148185.html?spm=a2c4g.11186623.6.544.7a567344OYxlfL

3.4  数据同步服务-精卫
精卫是一个基于MySQL数据库的数据复制中间件，通过复制管道达到数据共享的目的，在不同类型的存储（RDBMS，NoSQL，倒排序等）之间构建数据流动的管道。

精卫中间件的数据同步机制：它是分析mysql binlog ，解析成RowChangeEvent以后，通过上传jar包配置，进行对应的下游处理。

一般的处理方式为接受到binlog的变更event后，将对应event通过消息队列形式发送。

3.5  数据血缘分析-Druid解析器
DruidSql解析器 是一种基于抽象语法树AST构建的高性能SQL解析器。

SqlParser会根据指定数据库方言（mysql、oracle等）对sql进行语法、词法分析，并通过parser逻辑将sql解析成一颗AST语法树。

用户通过递归遍历语法树，可以获取到sql每一段逻辑包含的信息，包括SELECT块，FROM块，WHERE块，GROUP BY块，ORDER BY块，LIMIT块，HAVING块，并根据这些信息分析得到自己所需要的内容。

4、数仓详细设计
4.1 数仓元数据


4.1.1 表结构定义
数仓载体为adb表，其中表结构包括：

1）表名

2）表类型

表的类型分为原子表、视图表。

原子表可以理解为ods层表，作用为从业务库抽取基础数据；

视图表为上层表，包含dwd→dws→ads，作用为聚合基础业务数据，拉成宽链表，提供给上层业务使用。

3）字段

字段包括字段名，字段类型，字段注释

4）主键

支持单字段作为主键，也支持联合主键，作用为保证主键数据唯一性。

实时视图表中，需要把主链路的id设为联合主键，保证链路数据唯一，同时后续解析sql用于导入时，也会依赖这份主键数据。

5）一级分区键

维度表：DISTRIBUTED BY BROADCAST 用于定义维度表，维度表会在集群的每个节点存储一份数据，因此建议维度表的数据量不宜太大。

事实表：DISTRIBUTED BY HASH(column_name,...) 在表中定义表的分布键，按照column_name的HASH值进行分片

6）二级分区键、生命周期

表中定义分区。 通过LIFECYCLE N方式实现表生命周期管理，即对分区进行排序，超出N的分区将被过滤掉。

PARTITION BY VALUE(DATE_FORMAT(column_name, '%Y%m%d')) LIFECYCLE 365 表示将column_name格式化为类似20190101的日期格式做分区。表示每个节点最多保留的分区个数为365，即如果数据保存天数为365天，则第366天写入数据后，系统会自动删除第1天写入的数据。

4.1.2 数据来源定义
原子表：
1）source_db.source_table：源库.源表，支持一张原子表数据来源多份源表

2）field_mapping：source_db.source_table字段 -> 原子表字段的映射关系

3）filter：支持简单的where块作为过滤条件，比如is_deleted = 0

视图表：
1）source_db：需要执行sql语句的adb库，用于定义执行聚合原子表sql的查询在哪个库执行

2）view_sql：视图表的sql，即一段符合语法的sql语句，用于聚合原子表数据

4.1.3 动态规则
系统统一提供一个interface，提供接口方法executeRule(data)，可用于自定义接口实现。

接口实现为一段java代码，java类需要实现interface，并覆写executeRule(data)方法，表示对指定data进行java操作，此处操作可以包含rpc调用、数据库直接查询、java工具类执行等。

保存java类代码后，规则会在应用启动时动态编译，并在数据导入的时候进行规则执行。



规则的作用为udf，通过简单易用的java代码方式，提供对数据的加工。

4.2  数据血缘
原子表血缘：
原子表 -> 源库.源表

视图表血缘：
通过DruidSql解析器，解析视图表的view_sql，可以得到一整颗完整的语法树，取树中的SQLTableSource部分作为视图表依赖的table，从而得到整个视图表依赖哪些哪些底层表

4.3  数据全量导入（正向链路）
4.3.1 原子表全量导入


由于原子表的数据源是业务库，直接通过 SELECT field1,field2, ……, fieldn FROM source_table order by id limit page, offset 形式的sql语句能够直接的获取分页数据，并发查询性能较好

生成数据内部键inner_id：
直接使用 source_db.source_table.id 格式数据作为内部id

replace into
为adb语法，用于实时覆盖写入数据。写入数据时，会先根据主键判断待写入的数据是否已经存在于表中，并根据判断结果选择不同的方式写入数据： 如果待写入数据已经存在，则先删除该行数据，然后插入新的数据。 如果待写入数据不存在，则直接插入新数据。

语法介绍：https://help.aliyun.com/document_detail/123585.html?spm=a2c4g.11186623.6.776.4062c047FJP6k0

update into
为adb语法，用于更新指定字段。更新数据时，会先根据主键判断待更新的数据是否已经存在，若数据已存在，update指定的字段为新的值，若不存在，则不更新。



4.3.2 实时视图表全量导入


生成数据内部键inner_id：
根据实时视图所有主键，将数据的主键数值通过 “·” 分割拼接成key1.key2.…….keyn字符串后，加密处理成密文字符串作为内部id

提前主键查询的意义：
由于实时视图表的view_sql一般都比较大，涉及字段往往会达到上百个，如果直接执行order by 主键list limit，进行查询，会导致全表扫描，性能比较差，而通过主键进行order by limit会从主键索引进行查询，避免了表扫描，性能较好。

后续根据主键id再次查询数据，即可通过主键索引直接得到对应的行的信息，此时再进行跳转即可节约随机IO。

4.3.3 无规则准实时视图表导入


create table as 语法：
ADB支持通过CREATE TABLE创建表，也支持通过CTAS将查询到的数据写入新表中。

语法介绍：https://help.aliyun.com/document_detail/175788.html?spm=5176.21213303.J_6028563670.7.6c663eda5rZEAq&scm=20140722.S_help%40%40%E6%96%87%E6%A1%A3%40%40175788.S_0.ID_175788-OR_s%2Bhelpproduct-V_1-P0_0

外表：
adb支持跨库创建外表，并通过内部的建立连接的形式进行跨库查询。

用法介绍：https://help.aliyun.com/document_detail/126398.html

insert overwrite into table select 语法：
insert overwrite into 是adb的一种事务写的语法，命令执行结束之前，目标表中的数据不会发生任何变化；命令执行结束后，系统自动一键切换将数据写入目标表中，目标表的原数据将被清空。

如果adb表中存在二级分区，则insert overwrite into的时候，会往对应的二级分区事物写入数据，而不会影响其他二级分区的数据，该功能可用于保留准实时调度历史刷新版本。

语法介绍：https://help.aliyun.com/document_detail/123824.html?spm=a2c4g.11186623.6.781.7f7763c8VdpE5I

4.3.4 有规则准实时视图表导入


为什么需要自增中间表：
adb由于是全字段索引的特性，执行SELECT查询时，如果不指定ORDER BY，查询结果是无序的，所以无法通过直接limit的方式进行分页查询。

理论上这里可以直接通过uuid作为主键，但是order by uuid的性能，必然是没有自增主键好的，因为uuid的随机性会导致数据以碎片形式分布。

导入过程的并发处理：
这里采用了预热线程和数据处理线程两个线程池进行处理，其作用为：

1、每次limit1000的分页查询，依次执行20次，从对数据库压力、性能角度来说，都不如一次查询limit20000条数据；而直接查询20000条数据执行规则，会存在规则本身调用外界数据存在限制，大部分接口无法支持根据20000条数据进行处理。

2、以一个分段数据为20000条定义，预热线程可以提前2个分段进行数据预热，即数据处理线程还在处理第一个分段的数据时，预热线程已经可以提前读取第三分段的20000条数据，减少等待分页查询的时间。

3、分段锁的使用：由于数据处理线程是并发执行从预热数据中取数的过程，而取数据的过程会存在并发性问题，这里通过分段锁对取数过程进行加锁，即会对每一份数据采用一个单独的锁，不同份的数据之间的取数据过程并不会互斥，能够减少锁的竞争开销。



4.4  数据增量处理（逆向链路）


增量流程核心点在于，分析上游数据变更对下游视图表产生影响，而这个流程由于分析能力，逆向推理不支持sql包含子查询、union语句等复杂语句块，仅支持已定义好主键为链路的view_sql

场景比较繁多，列举其中部分涉及的场景：

1）主节点新增数据（需要新增行）

2）主节点变更字段（SQL血缘有使用、SQL血缘无使用）

3）主节点删除数据（需要判断是否会引起行的删除）

4）非主节点新增数据（需要判断是否会引起行的新增）

5）非主节点编辑数据（SQL血缘有使用、SQL血缘无使用）

6）非主节点删除数据（需要判断是否会引起行的删除、行的变更）

4.5  准实时数据调度服务


准实时数据调度服务，核心是通过队列和定时轮询任务，对上游事件和系统调度进行解耦，并且可以通过轮询任务内部逻辑，限制了调度任务的频率以及调度任务的并发量，对adb数据库压力进行了风险控制。

并且通过这种方式，很好的解决了链式任务（依赖调度）的场景，上游任务完成后，只需根据下游依赖配置，即可将对应下游任务投放进队列之中，等待下一次的轮询任务即可。

4.6  数据对账、订正


对账支持数据类型
数据对账、订正仅针对实时数据进行（原子表、实时视图表），准实时表数据通过调度写入，不在系统层面进行数据对账，接入数据监控系统，用于校验数据业务准确性。

布隆过滤器的意义
将所有获取到的source的数据，写入布隆过滤器，再通过遍历所有库内数据，能够通过内存处理的高性能快速的筛选出onlyDb的数据。

doubleCheck的作用
由于数仓是实时的，存在大量的增量数据变更，所以firstCheck的过程中，可能存在getFromource和getFromDb的过程中数据已经存在差异的问题，对账存在不准确的问题，通过doubleCheck对第一次校验出的差异进行二次source和db的对比，排除这部分数据差异问题。



5、系统不足
自研数仓解析，不支持复杂的sql的增量处理，仅支持全量数据定时调度，对数仓压力较大。

当前社区的实时数仓架构已经广泛使用flink的流处理和批处理，基于flink的source→sink，可以更高效的实现实时数仓的增量处理。

区别于传统sql的一次查询、固定结果，flink的流式处理、基于state的计算更适合时时刻刻变化的数据源。


